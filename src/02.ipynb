{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考\n",
    "# https://qiita.com/gensal/items/03e9a6d0f7081e77ba37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tifffile import TiffFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16_bn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../platelet_data'\n",
    "\n",
    "with TiffFile(os.path.join(data_dir, 'train-images.tif')) as tif:\n",
    "    train_img = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'train-labels.tif')) as tif:\n",
    "    train_label = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'eval-images.tif')) as tif:\n",
    "    eval_img = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'eval-labels.tif')) as tif:\n",
    "    eval_label = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'test-images.tif')) as tif:\n",
    "    test_img = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'test-labels.tif')) as tif:\n",
    "    test_label = tif.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = max(np.max(train_img), np.max(eval_img), np.max(test_img))\n",
    "m = min(np.min(train_img), np.min(eval_img), np.min(test_img))\n",
    "train_img_norm = (train_img - m) / (M - m)\n",
    "eval_img_norm = (eval_img - m) / (M - m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1]], dtype=uint16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = train_label[0]\n",
    "print(label.shape)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]], dtype=torch.int16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.from_numpy(label.astype(np.int16))\n",
    "print(label.shape)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label.long()\n",
    "print(label.shape)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 800, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.nn.functional.one_hot(label, num_classes=7)\n",
    "print(label.shape)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 800, 800])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label.to(torch.float32)\n",
    "label = label.permute(2, 0, 1)\n",
    "print(label.shape)\n",
    "label[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.29224105, 0.28794763, 0.27185214, ..., 0.16621101, 0.15968425,\n",
       "        0.18733154],\n",
       "       [0.29041201, 0.2864459 , 0.28919908, ..., 0.14849827, 0.14524451,\n",
       "        0.15616095],\n",
       "       [0.29035425, 0.28727378, 0.27456681, ..., 0.17294956, 0.17814786,\n",
       "        0.17216018],\n",
       "       ...,\n",
       "       [0.21216789, 0.22475934, 0.21274548, ..., 0.10785522, 0.12606854,\n",
       "        0.12757027],\n",
       "       [0.17462457, 0.18203697, 0.19162495, ..., 0.11160955, 0.1406238 ,\n",
       "        0.14597613],\n",
       "       [0.19928764, 0.18492491, 0.16105121, ..., 0.12724297, 0.11033885,\n",
       "        0.10375433]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = train_img_norm[0]\n",
    "print(image.shape)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 800, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.ToTensor()(image).shape\n",
    "transforms.ToTensor()(image)\n",
    "transforms.ToTensor()(image).permute(1, 2, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = torch.from_numpy(label.astype(np.int64)).clone()\n",
    "        label = torch.nn.functional.one_hot(label.long(), num_classes=7)\n",
    "        label = label.to(torch.float32)\n",
    "        label = label.permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transformations (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert numpy array to PyTorch Tensor\n",
    "    # Add additional transformations here if required\n",
    "])\n",
    "\n",
    "\n",
    "# Creating the datasets\n",
    "train_dataset = CustomDataset(train_img_norm, train_label, transform=transform)\n",
    "eval_dataset = CustomDataset(eval_img_norm, eval_label, transform=transform)\n",
    "\n",
    "# DataLoader creation\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2792, 0.2540, 0.2778,  ..., 0.0720, 0.0688, 0.0777],\n",
       "         [0.2843, 0.2874, 0.2796,  ..., 0.0576, 0.0887, 0.0880],\n",
       "         [0.2452, 0.2731, 0.2922,  ..., 0.0762, 0.0782, 0.1064],\n",
       "         ...,\n",
       "         [0.1566, 0.1436, 0.1157,  ..., 0.0972, 0.1052, 0.1111],\n",
       "         [0.1813, 0.1771, 0.1658,  ..., 0.1242, 0.1452, 0.1126],\n",
       "         [0.1536, 0.1423, 0.1382,  ..., 0.1231, 0.1394, 0.1448]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.rl = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.rl(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl(x)\n",
    "        return x\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "class UNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.TCB1 = TwoConvBlock(1, 64, 64)\n",
    "        self.TCB2 = TwoConvBlock(64, 128, 128)\n",
    "        self.TCB3 = TwoConvBlock(128, 256, 256)\n",
    "        self.TCB4 = TwoConvBlock(256, 512, 512)\n",
    "        self.TCB5 = TwoConvBlock(512, 1024, 1024)\n",
    "        self.TCB6 = TwoConvBlock(1024, 512, 512)\n",
    "        self.TCB7 = TwoConvBlock(512, 256, 256)\n",
    "        self.TCB8 = TwoConvBlock(256, 128, 128)\n",
    "        self.TCB9 = TwoConvBlock(128, 64, 64)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride = 2)\n",
    "        \n",
    "        self.UC1 = UpConv(1024, 512) \n",
    "        self.UC2 = UpConv(512, 256) \n",
    "        self.UC3 = UpConv(256, 128) \n",
    "        self.UC4= UpConv(128, 64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 7, kernel_size = 1)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.TCB1(x)\n",
    "        x1 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB2(x)\n",
    "        x2 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB3(x)\n",
    "        x3 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB4(x)\n",
    "        x4 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB5(x)\n",
    "\n",
    "        x = self.UC1(x)\n",
    "        x = torch.cat([x4, x], dim = 1)\n",
    "        x = self.TCB6(x)\n",
    "\n",
    "        x = self.UC2(x)\n",
    "        x = torch.cat([x3, x], dim = 1)\n",
    "        x = self.TCB7(x)\n",
    "\n",
    "        x = self.UC3(x)\n",
    "        x = torch.cat([x2, x], dim = 1)\n",
    "        x = self.TCB8(x)\n",
    "\n",
    "        x = self.UC4(x)\n",
    "        x = torch.cat([x1, x], dim = 1)\n",
    "        x = self.TCB9(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet = UNet_2D().to(device)\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.001)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m summary(unet, (\u001b[39m1\u001b[39;49m, \u001b[39m800\u001b[39;49m, \u001b[39m800\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mTCB1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     x1 \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device"
     ]
    }
   ],
   "source": [
    "summary(unet, (1, 800, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 800, 800])\n",
      "torch.Size([4, 7, 800, 800])\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imyu/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1009.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 13.88 GB, other allocations: 3.95 GB, max allowed: 18.13 GB). Tried to allocate 1.22 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(inputs\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m outputs \u001b[39m=\u001b[39m unet(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 17\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x2, x], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTCB8(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mUC4(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x1, x], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTCB9(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 13.88 GB, other allocations: 3.95 GB, max allowed: 18.13 GB). Tried to allocate 1.22 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "history = {\"train_loss\": []}\n",
    "n = 0\n",
    "m = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "  train_loss = 0\n",
    "  val_loss = 0\n",
    "\n",
    "  unet.train()\n",
    "  for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    inputs = inputs.float().to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    print(inputs.dtype)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = unet(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    history[\"train_loss\"].append(loss.item())\n",
    "    n += 1\n",
    "    # if i % ((len(df)//BATCH_SIZE)//10) == (len(df)//BATCH_SIZE)//10 - 1:\n",
    "    print(f\"epoch:{epoch+1}  index:{i+1}  train_loss:{train_loss/n:.5f}\")\n",
    "    n = 0\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "\n",
    "  unet.eval()\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(eval_loader):\n",
    "      inputs, labels = data\n",
    "      inputs = inputs.float().to(device)\n",
    "      labels = labels.float().to(device)\n",
    "      outputs = unet(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_loss += loss.item()\n",
    "      m += 1\n",
    "      # if i % (len(val_df)//BATCH_SIZE) == len(val_df)//BATCH_SIZE - 1:\n",
    "      print(f\"epoch:{epoch+1}  index:{i+1}  val_loss:{val_loss/m:.5f}\")\n",
    "      m = 0\n",
    "      val_loss = 0\n",
    "      val_acc = 0\n",
    "\n",
    "  # torch.save(unet.state_dict(), f\"./train_{epoch+1}.pth\")\n",
    "print(\"finish training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再起動（モデルを小さくして回してみる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tifffile import TiffFile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16_bn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../platelet_data'\n",
    "\n",
    "with TiffFile(os.path.join(data_dir, 'train-images.tif')) as tif:\n",
    "    train_img = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'train-labels.tif')) as tif:\n",
    "    train_label = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'eval-images.tif')) as tif:\n",
    "    eval_img = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'eval-labels.tif')) as tif:\n",
    "    eval_label = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'test-images.tif')) as tif:\n",
    "    test_img = tif.asarray()\n",
    "    \n",
    "with TiffFile(os.path.join(data_dir, 'test-labels.tif')) as tif:\n",
    "    test_label = tif.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = max(np.max(train_img), np.max(eval_img), np.max(test_img))\n",
    "m = min(np.min(train_img), np.min(eval_img), np.min(test_img))\n",
    "train_img_norm = (train_img - m) / (M - m)\n",
    "eval_img_norm = (eval_img - m) / (M - m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = torch.from_numpy(label.astype(np.int64)).clone()\n",
    "        label = torch.nn.functional.one_hot(label.long(), num_classes=7)\n",
    "        label = label.to(torch.float32)\n",
    "        label = label.permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transformations (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Resize((800, 800)),\n",
    "    # Add additional transformations here if required\n",
    "])\n",
    "\n",
    "\n",
    "# Creating the datasets\n",
    "train_dataset = CustomDataset(train_img_norm, train_label, transform=transform)\n",
    "eval_dataset = CustomDataset(eval_img_norm, eval_label, transform=transform)\n",
    "\n",
    "# DataLoader creation\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.rl = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.rl(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl(x)\n",
    "        return x\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.TCB1 = TwoConvBlock(1, 32, 32)\n",
    "        self.TCB2 = TwoConvBlock(32, 64, 64)\n",
    "        self.TCB3 = TwoConvBlock(64, 128, 128)\n",
    "        self.TCB4 = TwoConvBlock(128, 256, 256)\n",
    "        self.TCB5 = TwoConvBlock(256, 512, 512)\n",
    "        self.TCB6 = TwoConvBlock(512, 256, 256)\n",
    "        self.TCB7 = TwoConvBlock(256, 128, 128)\n",
    "        self.TCB8 = TwoConvBlock(128, 64, 64)\n",
    "        self.TCB9 = TwoConvBlock(64, 32, 32)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride = 2)\n",
    "        \n",
    "        self.UC1 = UpConv(512, 256) \n",
    "        self.UC2 = UpConv(256, 128) \n",
    "        self.UC3 = UpConv(128, 64) \n",
    "        self.UC4= UpConv(64, 32)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(32, 7, kernel_size = 1)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.TCB1(x)\n",
    "        x1 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB2(x)\n",
    "        x2 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB3(x)\n",
    "        x3 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB4(x)\n",
    "        x4 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB5(x)\n",
    "\n",
    "        x = self.UC1(x)\n",
    "        x = torch.cat([x4, x], dim = 1)\n",
    "        x = self.TCB6(x)\n",
    "\n",
    "        x = self.UC2(x)\n",
    "        x = torch.cat([x3, x], dim = 1)\n",
    "        x = self.TCB7(x)\n",
    "\n",
    "        x = self.UC3(x)\n",
    "        x = torch.cat([x2, x], dim = 1)\n",
    "        x = self.TCB8(x)\n",
    "\n",
    "        x = self.UC4(x)\n",
    "        x = torch.cat([x1, x], dim = 1)\n",
    "        x = self.TCB9(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# summary用 mpsだとうまくいかない\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet = UNet_2D().to(device)\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.001)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imyu/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1009.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 800, 800]             320\n",
      "       BatchNorm2d-2         [-1, 32, 800, 800]              64\n",
      "              ReLU-3         [-1, 32, 800, 800]               0\n",
      "            Conv2d-4         [-1, 32, 800, 800]           9,248\n",
      "       BatchNorm2d-5         [-1, 32, 800, 800]              64\n",
      "              ReLU-6         [-1, 32, 800, 800]               0\n",
      "      TwoConvBlock-7         [-1, 32, 800, 800]               0\n",
      "         MaxPool2d-8         [-1, 32, 400, 400]               0\n",
      "            Conv2d-9         [-1, 64, 400, 400]          18,496\n",
      "      BatchNorm2d-10         [-1, 64, 400, 400]             128\n",
      "             ReLU-11         [-1, 64, 400, 400]               0\n",
      "           Conv2d-12         [-1, 64, 400, 400]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 400, 400]             128\n",
      "             ReLU-14         [-1, 64, 400, 400]               0\n",
      "     TwoConvBlock-15         [-1, 64, 400, 400]               0\n",
      "        MaxPool2d-16         [-1, 64, 200, 200]               0\n",
      "           Conv2d-17        [-1, 128, 200, 200]          73,856\n",
      "      BatchNorm2d-18        [-1, 128, 200, 200]             256\n",
      "             ReLU-19        [-1, 128, 200, 200]               0\n",
      "           Conv2d-20        [-1, 128, 200, 200]         147,584\n",
      "      BatchNorm2d-21        [-1, 128, 200, 200]             256\n",
      "             ReLU-22        [-1, 128, 200, 200]               0\n",
      "     TwoConvBlock-23        [-1, 128, 200, 200]               0\n",
      "        MaxPool2d-24        [-1, 128, 100, 100]               0\n",
      "           Conv2d-25        [-1, 256, 100, 100]         295,168\n",
      "      BatchNorm2d-26        [-1, 256, 100, 100]             512\n",
      "             ReLU-27        [-1, 256, 100, 100]               0\n",
      "           Conv2d-28        [-1, 256, 100, 100]         590,080\n",
      "      BatchNorm2d-29        [-1, 256, 100, 100]             512\n",
      "             ReLU-30        [-1, 256, 100, 100]               0\n",
      "     TwoConvBlock-31        [-1, 256, 100, 100]               0\n",
      "        MaxPool2d-32          [-1, 256, 50, 50]               0\n",
      "           Conv2d-33          [-1, 512, 50, 50]       1,180,160\n",
      "      BatchNorm2d-34          [-1, 512, 50, 50]           1,024\n",
      "             ReLU-35          [-1, 512, 50, 50]               0\n",
      "           Conv2d-36          [-1, 512, 50, 50]       2,359,808\n",
      "      BatchNorm2d-37          [-1, 512, 50, 50]           1,024\n",
      "             ReLU-38          [-1, 512, 50, 50]               0\n",
      "     TwoConvBlock-39          [-1, 512, 50, 50]               0\n",
      "         Upsample-40        [-1, 512, 100, 100]               0\n",
      "      BatchNorm2d-41        [-1, 512, 100, 100]           1,024\n",
      "           Conv2d-42        [-1, 256, 100, 100]         524,544\n",
      "      BatchNorm2d-43        [-1, 256, 100, 100]             512\n",
      "           UpConv-44        [-1, 256, 100, 100]               0\n",
      "           Conv2d-45        [-1, 256, 100, 100]       1,179,904\n",
      "      BatchNorm2d-46        [-1, 256, 100, 100]             512\n",
      "             ReLU-47        [-1, 256, 100, 100]               0\n",
      "           Conv2d-48        [-1, 256, 100, 100]         590,080\n",
      "      BatchNorm2d-49        [-1, 256, 100, 100]             512\n",
      "             ReLU-50        [-1, 256, 100, 100]               0\n",
      "     TwoConvBlock-51        [-1, 256, 100, 100]               0\n",
      "         Upsample-52        [-1, 256, 200, 200]               0\n",
      "      BatchNorm2d-53        [-1, 256, 200, 200]             512\n",
      "           Conv2d-54        [-1, 128, 200, 200]         131,200\n",
      "      BatchNorm2d-55        [-1, 128, 200, 200]             256\n",
      "           UpConv-56        [-1, 128, 200, 200]               0\n",
      "           Conv2d-57        [-1, 128, 200, 200]         295,040\n",
      "      BatchNorm2d-58        [-1, 128, 200, 200]             256\n",
      "             ReLU-59        [-1, 128, 200, 200]               0\n",
      "           Conv2d-60        [-1, 128, 200, 200]         147,584\n",
      "      BatchNorm2d-61        [-1, 128, 200, 200]             256\n",
      "             ReLU-62        [-1, 128, 200, 200]               0\n",
      "     TwoConvBlock-63        [-1, 128, 200, 200]               0\n",
      "         Upsample-64        [-1, 128, 400, 400]               0\n",
      "      BatchNorm2d-65        [-1, 128, 400, 400]             256\n",
      "           Conv2d-66         [-1, 64, 400, 400]          32,832\n",
      "      BatchNorm2d-67         [-1, 64, 400, 400]             128\n",
      "           UpConv-68         [-1, 64, 400, 400]               0\n",
      "           Conv2d-69         [-1, 64, 400, 400]          73,792\n",
      "      BatchNorm2d-70         [-1, 64, 400, 400]             128\n",
      "             ReLU-71         [-1, 64, 400, 400]               0\n",
      "           Conv2d-72         [-1, 64, 400, 400]          36,928\n",
      "      BatchNorm2d-73         [-1, 64, 400, 400]             128\n",
      "             ReLU-74         [-1, 64, 400, 400]               0\n",
      "     TwoConvBlock-75         [-1, 64, 400, 400]               0\n",
      "         Upsample-76         [-1, 64, 800, 800]               0\n",
      "      BatchNorm2d-77         [-1, 64, 800, 800]             128\n",
      "           Conv2d-78         [-1, 32, 800, 800]           8,224\n",
      "      BatchNorm2d-79         [-1, 32, 800, 800]              64\n",
      "           UpConv-80         [-1, 32, 800, 800]               0\n",
      "           Conv2d-81         [-1, 32, 800, 800]          18,464\n",
      "      BatchNorm2d-82         [-1, 32, 800, 800]              64\n",
      "             ReLU-83         [-1, 32, 800, 800]               0\n",
      "           Conv2d-84         [-1, 32, 800, 800]           9,248\n",
      "      BatchNorm2d-85         [-1, 32, 800, 800]              64\n",
      "             ReLU-86         [-1, 32, 800, 800]               0\n",
      "     TwoConvBlock-87         [-1, 32, 800, 800]               0\n",
      "           Conv2d-88          [-1, 7, 800, 800]             231\n",
      "================================================================\n",
      "Total params: 7,768,487\n",
      "Trainable params: 7,768,487\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.44\n",
      "Forward/backward pass size (MB): 6328.12\n",
      "Params size (MB): 29.63\n",
      "Estimated Total Size (MB): 6360.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(unet, (1, 800, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# 回す用\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet = UNet_2D().to(device)\n",
    "optimizer = optim.Adam(unet.parameters(), lr=0.001)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_sizeを小さくしてようやく回る\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "def criterion(output, target):\n",
    "    return nn.BCEWithLogitsLoss()(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imyu/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1690826002332/work/aten/src/ATen/native/Convolution.cpp:1004.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1  index:1  train_loss:0.68925\n",
      "epoch:1  index:2  train_loss:0.63738\n",
      "epoch:1  index:3  train_loss:0.61883\n",
      "epoch:1  index:4  train_loss:0.58864\n",
      "epoch:1  index:5  train_loss:0.57221\n",
      "epoch:1  index:6  train_loss:0.55420\n",
      "epoch:1  index:7  train_loss:0.53134\n",
      "epoch:1  index:8  train_loss:0.51565\n",
      "epoch:1  index:9  train_loss:0.52702\n",
      "epoch:1  index:10  train_loss:0.52750\n",
      "epoch:1  index:11  train_loss:0.48848\n",
      "epoch:1  index:12  train_loss:0.50582\n",
      "epoch:1  index:13  train_loss:0.49994\n",
      "epoch:1  index:14  train_loss:0.49664\n",
      "epoch:1  index:15  train_loss:0.49015\n",
      "epoch:1  index:16  train_loss:0.46216\n",
      "epoch:1  index:17  train_loss:0.45426\n",
      "epoch:1  index:18  train_loss:0.44652\n",
      "epoch:1  index:19  train_loss:0.46410\n",
      "epoch:1  index:20  train_loss:0.43090\n",
      "epoch:1  index:21  train_loss:0.42504\n",
      "epoch:1  index:22  train_loss:0.41937\n",
      "epoch:1  index:23  train_loss:0.46461\n",
      "epoch:1  index:24  train_loss:0.43729\n",
      "epoch:1  index:25  train_loss:0.42400\n",
      "epoch:1  index:26  train_loss:0.40610\n",
      "epoch:1  index:27  train_loss:0.39803\n",
      "epoch:1  index:28  train_loss:0.43416\n",
      "epoch:1  index:29  train_loss:0.43086\n",
      "epoch:1  index:30  train_loss:0.42624\n",
      "epoch:1  index:31  train_loss:0.41163\n",
      "epoch:1  index:32  train_loss:0.41848\n",
      "epoch:1  index:33  train_loss:0.41357\n",
      "epoch:1  index:34  train_loss:0.38019\n",
      "epoch:1  index:35  train_loss:0.37079\n",
      "epoch:1  index:36  train_loss:0.38862\n",
      "epoch:1  index:37  train_loss:0.39351\n",
      "epoch:1  index:38  train_loss:0.38559\n",
      "epoch:1  index:39  train_loss:0.35941\n",
      "epoch:1  index:40  train_loss:0.39292\n",
      "epoch:1  index:41  train_loss:0.36281\n",
      "epoch:1  index:42  train_loss:0.38928\n",
      "epoch:1  index:43  train_loss:0.37315\n",
      "epoch:1  index:44  train_loss:0.36851\n",
      "epoch:1  index:45  train_loss:0.34768\n",
      "epoch:1  index:46  train_loss:0.35715\n",
      "epoch:1  index:47  train_loss:0.36948\n",
      "epoch:1  index:48  train_loss:0.32790\n",
      "epoch:1  index:49  train_loss:0.34440\n",
      "epoch:1  index:50  train_loss:0.32010\n",
      "epoch:1  index:1  val_loss:0.63117\n",
      "epoch:1  index:2  val_loss:0.63651\n",
      "epoch:1  index:3  val_loss:0.64040\n",
      "epoch:1  index:4  val_loss:0.63664\n",
      "epoch:1  index:5  val_loss:0.64575\n",
      "epoch:1  index:6  val_loss:0.64524\n",
      "epoch:1  index:7  val_loss:0.65442\n",
      "epoch:1  index:8  val_loss:0.67048\n",
      "epoch:1  index:9  val_loss:0.67511\n",
      "epoch:1  index:10  val_loss:0.67756\n",
      "epoch:1  index:11  val_loss:0.68258\n",
      "epoch:1  index:12  val_loss:0.68175\n",
      "epoch:1  index:13  val_loss:0.68150\n",
      "epoch:1  index:14  val_loss:0.68402\n",
      "epoch:1  index:15  val_loss:0.68339\n",
      "epoch:1  index:16  val_loss:0.68457\n",
      "epoch:1  index:17  val_loss:0.68780\n",
      "epoch:1  index:18  val_loss:0.67885\n",
      "epoch:1  index:19  val_loss:0.67364\n",
      "epoch:1  index:20  val_loss:0.66984\n",
      "epoch:1  index:21  val_loss:0.66010\n",
      "epoch:1  index:22  val_loss:0.65645\n",
      "epoch:1  index:23  val_loss:0.64474\n",
      "epoch:1  index:24  val_loss:0.64129\n",
      "epoch:2  index:1  train_loss:0.31553\n",
      "epoch:2  index:2  train_loss:0.36010\n",
      "epoch:2  index:3  train_loss:0.35795\n",
      "epoch:2  index:4  train_loss:0.33899\n",
      "epoch:2  index:5  train_loss:0.30377\n",
      "epoch:2  index:6  train_loss:0.33241\n",
      "epoch:2  index:7  train_loss:0.31972\n",
      "epoch:2  index:8  train_loss:0.34389\n",
      "epoch:2  index:9  train_loss:0.33110\n",
      "epoch:2  index:10  train_loss:0.29176\n",
      "epoch:2  index:11  train_loss:0.31369\n",
      "epoch:2  index:12  train_loss:0.31653\n",
      "epoch:2  index:13  train_loss:0.28015\n",
      "epoch:2  index:14  train_loss:0.28966\n",
      "epoch:2  index:15  train_loss:0.27357\n",
      "epoch:2  index:16  train_loss:0.32136\n",
      "epoch:2  index:17  train_loss:0.26777\n",
      "epoch:2  index:18  train_loss:0.29502\n",
      "epoch:2  index:19  train_loss:0.31087\n",
      "epoch:2  index:20  train_loss:0.30898\n",
      "epoch:2  index:21  train_loss:0.30338\n",
      "epoch:2  index:22  train_loss:0.30340\n",
      "epoch:2  index:23  train_loss:0.29622\n",
      "epoch:2  index:24  train_loss:0.28833\n",
      "epoch:2  index:25  train_loss:0.28753\n",
      "epoch:2  index:26  train_loss:0.25850\n",
      "epoch:2  index:27  train_loss:0.25907\n",
      "epoch:2  index:28  train_loss:0.25326\n",
      "epoch:2  index:29  train_loss:0.25134\n",
      "epoch:2  index:30  train_loss:0.23862\n",
      "epoch:2  index:31  train_loss:0.28446\n",
      "epoch:2  index:32  train_loss:0.26492\n",
      "epoch:2  index:33  train_loss:0.23240\n",
      "epoch:2  index:34  train_loss:0.28035\n",
      "epoch:2  index:35  train_loss:0.22966\n",
      "epoch:2  index:36  train_loss:0.26100\n",
      "epoch:2  index:37  train_loss:0.25491\n",
      "epoch:2  index:38  train_loss:0.23381\n",
      "epoch:2  index:39  train_loss:0.24206\n",
      "epoch:2  index:40  train_loss:0.24098\n",
      "epoch:2  index:41  train_loss:0.25012\n",
      "epoch:2  index:42  train_loss:0.22589\n",
      "epoch:2  index:43  train_loss:0.20951\n",
      "epoch:2  index:44  train_loss:0.24027\n",
      "epoch:2  index:45  train_loss:0.25115\n",
      "epoch:2  index:46  train_loss:0.20083\n",
      "epoch:2  index:47  train_loss:0.23485\n",
      "epoch:2  index:48  train_loss:0.23871\n",
      "epoch:2  index:49  train_loss:0.23691\n",
      "epoch:2  index:50  train_loss:0.19509\n",
      "epoch:2  index:1  val_loss:1.31931\n",
      "epoch:2  index:2  val_loss:1.33296\n",
      "epoch:2  index:3  val_loss:1.33939\n",
      "epoch:2  index:4  val_loss:1.33165\n",
      "epoch:2  index:5  val_loss:1.35227\n",
      "epoch:2  index:6  val_loss:1.35086\n",
      "epoch:2  index:7  val_loss:1.37353\n",
      "epoch:2  index:8  val_loss:1.41062\n",
      "epoch:2  index:9  val_loss:1.42024\n",
      "epoch:2  index:10  val_loss:1.42416\n",
      "epoch:2  index:11  val_loss:1.43372\n",
      "epoch:2  index:12  val_loss:1.43400\n",
      "epoch:2  index:13  val_loss:1.43326\n",
      "epoch:2  index:14  val_loss:1.44018\n",
      "epoch:2  index:15  val_loss:1.44108\n",
      "epoch:2  index:16  val_loss:1.44474\n",
      "epoch:2  index:17  val_loss:1.45422\n",
      "epoch:2  index:18  val_loss:1.43049\n",
      "epoch:2  index:19  val_loss:1.42065\n",
      "epoch:2  index:20  val_loss:1.41134\n",
      "epoch:2  index:21  val_loss:1.38887\n",
      "epoch:2  index:22  val_loss:1.37863\n",
      "epoch:2  index:23  val_loss:1.35177\n",
      "epoch:2  index:24  val_loss:1.34197\n",
      "epoch:3  index:1  train_loss:0.19876\n",
      "epoch:3  index:2  train_loss:0.19119\n",
      "epoch:3  index:3  train_loss:0.22385\n",
      "epoch:3  index:4  train_loss:0.20033\n",
      "epoch:3  index:5  train_loss:0.22729\n",
      "epoch:3  index:6  train_loss:0.18812\n",
      "epoch:3  index:7  train_loss:0.20183\n",
      "epoch:3  index:8  train_loss:0.22206\n",
      "epoch:3  index:9  train_loss:0.20691\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# print(inputs.dtype)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m outputs \u001b[39m=\u001b[39m unet(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 28\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x4, x], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTCB6(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mUC2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x3, x], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTCB7(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/imyu/transx/kikagaku_seg/src/02.ipynb セル 28\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mup(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/imyu/transx/kikagaku_seg/src/02.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/modules/upsampling.py:156\u001b[0m, in \u001b[0;36mUpsample.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49minterpolate(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_factor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malign_corners,\n\u001b[1;32m    157\u001b[0m                          recompute_scale_factor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecompute_scale_factor)\n",
      "File \u001b[0;32m~/anaconda3/envs/seg/lib/python3.9/site-packages/torch/nn/functional.py:3959\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3957\u001b[0m     \u001b[39mif\u001b[39;00m antialias:\n\u001b[1;32m   3958\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39m_upsample_bilinear2d_aa(\u001b[39minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 3959\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mupsample_bilinear2d(\u001b[39minput\u001b[39;49m, output_size, align_corners, scale_factors)\n\u001b[1;32m   3960\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrilinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   3961\u001b[0m     \u001b[39massert\u001b[39;00m align_corners \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {\"train_loss\": []}\n",
    "n = 0\n",
    "m = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "  train_loss = 0\n",
    "  val_loss = 0\n",
    "\n",
    "  unet.train()\n",
    "  for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data\n",
    "    # print(inputs.shape)\n",
    "    # print(labels.shape)\n",
    "    inputs = inputs.float().to(device)\n",
    "    labels = labels.float().to(device)\n",
    "    # print(inputs.dtype)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = unet(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    history[\"train_loss\"].append(loss.item())\n",
    "    n += 1\n",
    "    # if i % ((len(df)//BATCH_SIZE)//10) == (len(df)//BATCH_SIZE)//10 - 1:\n",
    "    print(f\"epoch:{epoch+1}  index:{i+1}  train_loss:{train_loss/n:.5f}\")\n",
    "    n = 0\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "\n",
    "  unet.eval()\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(eval_loader):\n",
    "      inputs, labels = data\n",
    "      inputs = inputs.float().to(device)\n",
    "      labels = labels.float().to(device)\n",
    "      outputs = unet(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_loss += loss.item()\n",
    "      m += 1\n",
    "      # if i % (len(val_df)//BATCH_SIZE) == len(val_df)//BATCH_SIZE - 1:\n",
    "      print(f\"epoch:{epoch+1}  index:{i+1}  val_loss:{val_loss/m:.5f}\")\n",
    "      m = 0\n",
    "      val_loss = 0\n",
    "      val_acc = 0\n",
    "\n",
    "  # torch.save(unet.state_dict(), f\"./train_{epoch+1}.pth\")\n",
    "print(\"finish training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0003, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "tensor(0.0002, device='mps:0')\n",
      "0.0002141681\n"
     ]
    }
   ],
   "source": [
    "# valid meanIoU\n",
    "\n",
    "from torchmetrics.functional import jaccard_index\n",
    "\n",
    "scores = []\n",
    "\n",
    "unet.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(eval_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        outputs = unet(inputs)\n",
    "        print(jaccard_index(outputs, labels, num_classes=7, task=\"multiclass\"))\n",
    "        scores.append(jaccard_index(outputs, labels, num_classes=7, task=\"multiclass\").to(\"cpu\").numpy())\n",
    "        # print(jaccard_index(labels, labels, num_classes=7, task=\"multiclass\"))\n",
    "        \n",
    "print(np.mean(scores))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002141681\n"
     ]
    }
   ],
   "source": [
    "# scores = np.array(scores)\n",
    "# scores = scores.to(\"cpu\")\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
